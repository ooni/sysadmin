#!/bin/bash
#
# Ability to execute arbituary docker commands equals to root-shell, so this
# script does some whitelisting.  The script should be launched with:
#
#   sudo --non-interactive /foo/bar/trampoline.sh \
#         do-something-awesome.py \
#         "{{ ds }}" \
#         "{{ execution_date.isoformat() }}" \
#         "{{ (execution_date + dag.schedule_interval).isoformat() }}" \
#         other CLI arguments to script

# FIXME: 1000 = `id -u benchmark` at the datacollector dom0
uidno=1000

script="$1"
bucket="$2"
isofrom="$3" # execution_date
isotill="$4" # execution_date + schedule_interval
shift 4

(
shopt -s extglob
if [ -z "$bucket" -o -n "${bucket/+([-0-9])/}" ]; then
    echo "$0: bad arg <$bucket> -> <${bucket/+([-0-9])/}>" 1>&2
    exit 1
fi
for var in "$isofrom" "$isotill"; do
    if [ -z "$var" -o -n "${var/+([-0-9T:.])/}" ]; then
        echo "$0: bad arg <$var> -> <${var/+([-0-9T:.])/}>" 1>&2
        exit 1
    fi
done
) || exit 1

docksafe="--rm --interactive --read-only"
docknet="--network none"

private=/data/ooni/private
public=/data/ooni/public
volargs=""
case "$script" in
    reports_raw_sensor)
    volargs="${volargs} --volume=$private/reports-raw/${bucket}:$private/reports-raw/${bucket}:ro"
    volargs="${volargs} --volume=$private/reports-raw-shals:$private/reports-raw-shals:ro"
    exec docker run $docksafe $docknet $volargs debian:jessie \
        /bin/bash -c "set -o pipefail && find $private/reports-raw/${bucket} -type f -printf '%f %s\n' | LC_ALL=C sort --buffer-size=96M | sha256sum --check $private/reports-raw-shals/${bucket} && exit 42 || exit 13"
    ;;

    canning)
    docker run $docksafe --network none -v=$private/canned:$private/canned debian:jessie /bin/bash -c "mkdir -p $private/canned/${bucket} && chown $uidno $private/canned/${bucket}"
    volargs="${volargs} --volume=$private/reports-raw/${bucket}:$private/reports-raw/${bucket}:ro"
    volargs="${volargs} --volume=$private/canned/${bucket}:$private/canned/${bucket}:rw"
    volargs="${volargs} --tmpfs /tmp:rw,noexec,nosuid,size=128m"
    set -- /usr/local/bin/canning.py --start "$isofrom" --end "$isotill" \
        --reports-raw-root $private/reports-raw \
        --canned-root $private/canned
    ;;

    autoclaving)
    docker run $docksafe --network none -v=$public/autoclaved:$public/autoclaved debian:jessie /bin/bash -c "mkdir -p $public/autoclaved/${bucket} && chown $uidno $public/autoclaved/${bucket}"
    volargs="${volargs} --volume=$private/bridge_db:$private/bridge_db:ro"
    volargs="${volargs} --volume=$private/canned/${bucket}:$private/canned/${bucket}:ro"
    volargs="${volargs} --volume=$public/autoclaved/${bucket}:$public/autoclaved/${bucket}:rw"
    set -- /usr/local/bin/autoclaving.py --start "$isofrom" --end "$isotill" \
        --canned-root $private/canned \
        --bridge-db $private/bridge_db/bridge_db.json \
        --autoclaved-root $public/autoclaved
    ;;

    meta_pg)
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/hkgmetadb.env"
    volargs="${volargs} --volume=$public/autoclaved/${bucket}:$public/autoclaved/${bucket}:ro"
    set -- /usr/local/bin/centrifugation.py --start "$isofrom" --end "$isotill" \
        --autoclaved-root /data/ooni/public/autoclaved \
        --postgres "host=hkgmetadb.infra.ooni.io user=shovel dbname=metadb"
    ;;

    # WAL is flushed after `meta_pg` to ensure that hot replica is not affected
    # by 64+ subtransactions in the whole-bucket `meta_pg` transaction.
    # E.g. the transaction had 283 `subxacts` on 2019-04-21.  See also:
    # - https://github.com/ooni/sysadmin/issues/272#issuecomment-485418243
    # - https://www.postgresql.org/docs/9.6/hot-standby.html#HOT-STANDBY-CAVEATS
    meta_wal_flush)
    set -o xtrace
    # It may be postgres:9.6 as well, openobservatory/... is used only for consistency.
    exec docker run $docksafe --env-file=/etc/af-worker/hkgmetadb.env \
        openobservatory/sysadmin-postgres-metadb:20190412-010f6f70 \
        psql --host=hkgmetadb.infra.ooni.io --username=shovel --dbname=metadb \
        -c 'SELECT pg_switch_xlog()'
    exit 1 # if exec fails
    ;;

    tar_reports_raw)
    # some `reports-raw` buckets were already removed from datacollector and have to be restored from `.tar.lz4` for compression
    docker run $docksafe --network none -v=$private/reports-raw:$private/reports-raw debian:jessie /bin/bash -c "mkdir -p $private/reports-raw/${bucket} && chown $uidno $private/reports-raw/${bucket}"
    volargs="${volargs} --volume=$private/reports-tgz:$private/reports-tgz:rw"
    volargs="${volargs} --volume=$private/reports-raw/${bucket}:$private/reports-raw/${bucket}:rw"
    volargs="${volargs} --volume=$private/canned/${bucket}:$private/canned/${bucket}:ro"
    set -- /usr/local/bin/tar_reports_raw.py --bucket "$bucket" --reports-tgz "$private/reports-tgz" --reports-raw "$private/reports-raw" --canned "$private/canned"
    ;;

    reports_raw_cleanup)
    volargs="${volargs} --volume=$private/reports-tgz:$private/reports-tgz:ro"
    volargs="${volargs} --volume=$private/canned/${bucket}:$private/canned/${bucket}:ro"
    volargs="${volargs} --volume=$private/reports-raw/${bucket}:$private/reports-raw/${bucket}:rw"
    set -- /usr/local/bin/cleanup_reports_raw.py --bucket "${bucket}" --reports-raw-root "$private/reports-raw" --canned-index "$private/canned/${bucket}/index.json.gz" --reports-tgz-index "$private/reports-tgz/${bucket}.index.json.gz"
    ;;

    reports_tgz_s3_sync)
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/s3_ooni_datacollector.env"
    volargs="${volargs} --volume=$private/reports-tgz:$private/reports-tgz:ro"
    set -- aws s3 sync --size-only "$private/reports-tgz/" s3://ooni-data-private/archives-raw/yaml/ --exclude '*' --include "${bucket}.tar.gz" --include "${bucket}.index.json.gz"
    ;;

    reports_tgz_s3_ls)
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/s3_ooni_datacollector.env" # maybe downgrade to `list-only` user?
    volargs="${volargs} --volume=$private/reports-tgz-s3-ls:$private/reports-tgz-s3-ls:rw"
    set -- /usr/local/bin/aws_s3_ls.py --url "s3://ooni-data-private/archives-raw/yaml/$bucket" --s3-ls "$private/reports-tgz-s3-ls/${bucket}.json.gz"
    ;;

    reports_tgz_cleanup)
    volargs="${volargs} --volume=$private/reports-tgz-s3-ls:$private/reports-tgz-s3-ls:ro"
    volargs="${volargs} --volume=$private/reports-tgz:$private/reports-tgz:rw"
    set -- /usr/local/bin/cleanup_uploaded.py --dir "$private/reports-tgz" --s3-ls "$private/reports-tgz-s3-ls/${bucket}.json.gz" --exclude "$private/reports-tgz/${bucket}.index.json.gz"
    ;;

    canned_s3_sync)
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/s3_ooni_datacollector.env"
    volargs="${volargs} --volume=$private/canned/${bucket}:$private/canned/${bucket}:ro"
    set -- aws s3 sync --size-only "$private/canned/${bucket}/" "s3://ooni-data-private/canned/${bucket}/"
    ;;

    canned_s3_ls)
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/s3_ooni_datacollector.env" # maybe downgrade to `list-only` user?
    volargs="${volargs} --volume=$private/canned-s3-ls:$private/canned-s3-ls:rw"
    set -- /usr/local/bin/aws_s3_ls.py --url "s3://ooni-data-private/canned/$bucket" --s3-ls "$private/canned-s3-ls/${bucket}.json.gz"
    ;;

    canned_cleanup)
    volargs="${volargs} --volume=$private/canned/${bucket}:$private/canned/${bucket}:rw"
    docker run $docksafe $docknet $volargs debian:jessie chmod u+w "$private/canned/${bucket}" # it's marked as read-only when it's done
    volargs="${volargs} --volume=$private/canned-s3-ls:$private/canned-s3-ls:ro"
    set -- /usr/local/bin/cleanup_uploaded.py --dir "$private/canned/${bucket}" --s3-ls "$private/canned-s3-ls/${bucket}.json.gz" --exclude "$private/canned/${bucket}/index.json.gz"
    ;;

    autoclaved_tarlz4_s3_sync)
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/s3root.env"
    volargs="${volargs} --volume=$public/autoclaved/${bucket}:$public/autoclaved/${bucket}:ro"
    set -- aws s3 sync --size-only "$public/autoclaved/${bucket}/" "s3://ooni-data/autoclaved/jsonl.tar.lz4/${bucket}/"
    ;;

    autoclaved_jsonl_s3_sync)
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/s3root.env"
    volargs="${volargs} --volume=$public/autoclaved/${bucket}:$public/autoclaved/${bucket}:ro"
    # disk-backed /tmp may be preferred as the largest report ever is ~1.4Gb,
    # concurrent processing of alike reports may be affected. OTOH, the usual
    # size of scratchpad is ~64M and it probably should not be an issue.
    volargs="${volargs} --tmpfs /tmp:rw,noexec,nosuid,size=1536m"
    set -- /usr/local/bin/aws_s3_lz4cat_sync.py --src "$public/autoclaved/${bucket}" --s3-bucket "ooni-data" --s3-prefix "autoclaved/jsonl/${bucket}"
    ;;

    collector_sensor_*)
    fqdn="$1"
    ping -nq -c 5 -i 0.2 "$fqdn" || exit 1 # poor-man input validation
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/collector_ssh.env"
    volargs="${volargs} --volume=/srv/etc/collector_ssh:/etc/collector_ssh:ro"
    volargs="${volargs} --tmpfs /tmp:rw,noexec,nosuid,size=64m"
    # if it's non-empty and does not grow
    set -- /bin/bash -c 'set -ex; cd /tmp; mkfifo f; rsync "$0": >f & f=$(wc -l <f); wait -n; if [ $f -gt 1 ] && sleep 60 && [ $f -eq $(rsync "$0": | wc -l) ]; then exit 42; else exit 13; fi' "$fqdn"
    ;;

    rsync_collector_*)
    fqdn="$1"
    ping -nq -c 5 -i 0.2 "$fqdn" || exit 1 # poor-man input validation
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/collector_ssh.env"
    volargs="${volargs} --volume=/srv/etc/collector_ssh:/etc/collector_ssh:ro"
    volargs="${volargs} --volume=$private/spool/$fqdn:/spool/$fqdn:rw"
    set -- rsync --remove-source-files -azP "${fqdn}:" "/spool/$fqdn/"
    ;;

    reports_raw_merge)
    for fqdn in "$@"; do
        ping -nq -c 5 -i 0.2 "$fqdn" || exit 1 # poor-man input validation
    done
    docker run $docksafe --network none -v=$private/reports-raw:/reports-raw:rw debian:jessie /bin/bash -c "mkdir -p /reports-raw/${bucket} && chown $uidno /reports-raw/${bucket}"

    # NB: rename(2) can happen only within the same filesystem,
    # and two bind-mounts are considered two different FSes.
    # So whole /private subtree is mounted in the following code.
    volargs="${volargs} --volume=$private:/p:rw"

    # sort's `--buffer-size` is intentionally lower here then in another place: # if it fails because of RAM, checksum should differ.
    set -- /bin/bash -c 'set -ex; set -o pipefail; set -o noclobber; cd /p/spool; find "$@" -type f -execdir mv --no-clobber --target-directory "/p/reports-raw/$0" {} +; find "/p/reports-raw/$0/" -type f -printf "%f %s\n" | LC_ALL=C sort --buffer-size=64M | sha256sum >"/p/reports-raw-shals/$0"' "${bucket}" "$@"
    ;;

    sync_test_lists)
    docknet="" # no `--network none'
    volargs="${volargs} --env-file=/etc/af-worker/orchestradb.env"
    volargs="${volargs} --volume=/etc/ssl/ooca-cert:/ooca-cert:ro"
    volargs="${volargs} --tmpfs /tmp:rw,noexec,nosuid,size=64m"
    set -o xtrace
    exec docker run $docksafe --user "$uidno" $docknet ${volargs} \
      openobservatory/orchestra-scripts:20181206-3be1378e \
      sync-test-lists.py \
        --working-dir /tmp \
        --postgres 'host=db-1.proteus.ooni.io user=proteus dbname=proteus sslmode=verify-full sslrootcert=/ooca-cert/postgres_ca.cert'
    exit 1 # if exec fails
    ;;

    *)
    echo "$0: unknown script <$script>" 1>&2
    exit 1
    ;;
esac

# FIXME: hardcoded uid of the `benchmark` user at `datacollector`
set -o xtrace
exec docker run $docksafe --user "$uidno" $docknet ${volargs} openobservatory/pipeline-shovel:20190426-065cccdf "$@"
